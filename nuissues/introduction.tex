\section{Introduction}

\citeauthor{norman:natural-user-interfaces-are-not-natural:2010}'s (\citeyear{norman:natural-user-interfaces-are-not-natural:2010}) opinion piece \citetitle{norman:natural-user-interfaces-are-not-natural:2010} begins with the following quote from Steve Ballmer, CEO of Microsoft:

\begin{quote}
I believe we will look back on 2010 as the year we expanded beyond the mouse and keyboard, and started incorporating more natural forms of interaction such as touch, speech, gestures, handwriting, and vision -- what computer scientists call the 'NUI' or natural user interface."
\end{quote}

Following the quote, a statement is made:

\begin{quotation}
[\dots] A new world of interaction is here: The rulebooks and guidelines are being rewritten, or at least, such is the claim. And the new interactions even have a new marketing name: natural, as in "Natural User Interface."

As usual, marketing rhetoric is ahead of reality.    
\end{quotation}

\citeauthor{norman:natural-user-interfaces-are-not-natural:2010} is, of course, right: using Microsoft as an example, we have seen attempts at natural user interfaces in the direction of hybrid tablet computers like the Microsoft Surface, gesture trackers like Microsoft Kinect, and voice recognition in the personal assistant Cortana. Though efforts have certainly been made, we have mostly seen that Natural User Interfaces (NUIs) are just a new way to interact with the old (but sometimes slightly different-looking) interfaces we already know. A prime example how this application does not work without thought put into optimising for the task at hand is the "flat" look of Windows called "Metro" and then "Modern UI", which was supposed to fit \textit{all} Microsoft devices (desktops, laptops, tablets, and smartphones).

Natural User Interfaces are, indeed, a new way to interact with Graphical User Interfaces (GUIs), and not something completely new. However, as we move away from pen and mouse and into the domain of touch sensitivity, speech recognition, and several other "natural" interface types, we must also update the GUIs to suit the task at hand and the input type of choice.

For example, a tablet with a screen surface sensitive to both the natural interface of touch and the Tangible User Interface (TUI) \autocite{ishii-ullmer:tangible-bits-towards-seamless-interfaces-between-people-bits-and-atoms:1997} of stylus (pen) should immediately be able to differentiate between the two input types, because a user normally only wants to use the stylus for tasks fine-grained than what can be done just as efficiently by touching the screen with fingers: for example, sketching or annotating a document.

When it has been established that NUIs are new ways of interacting with GUIs and thus get all of the benefits (and restrictions) of the GUI's exploratory nature, we must of course learn from the GUI design and how we have interacted with them before to best design natural interaction experiences -- but looking to the past is far from enough. New guidelines must be written and revised before we can determine a common understanding of how natural user interfaces should be used. After all, \textcite{norman:natural-user-interfaces-are-not-natural:2010} calls them \textit{not natural}.

This report looks at an issue (task) tracker designed with guidelines and best practises for Natural User Interfaces in mind.  The board consists of three simple lists: \textbf{todo}, \textbf{doing}, and \textbf{done}. The user can interact with existing tasks and drag them between the lists.

The goal of the application and this report is to detemrmine how optimising a 2D interface for the natural interface type \textit{touch} can help boost productivity in a simple issue tracking system.
