\section{Introduction}

\citeauthor{norman:natural-user-interfaces-are-not-natural:2010}'s \citeyear{norman:natural-user-interfaces-are-not-natural:2010} opinion piece \citetitle{norman:natural-user-interfaces-are-not-natural:2010} begins with the following quote from Steve Ballmer, CEO of Microsoft:

\begin{quote}
I believe we will look back on 2010 as the year we expanded beyond the mouse and keyboard, and started incorporating more natural forms of interaction such as touch, speech, gestures, handwriting, and vision -- what computer scientists call the 'NUI' or natural user interface."
\end{quote}


Following the quotation, a statement is made:

\begin{quotation}
[\dots] A new world of interaction is here: The rulebooks and guidelines are being rewritten, or at least, such is the claim. And the new interactions even have a new marketing name: natural, as in "Natural User Interface."

As usual, marketing rhetoric is ahead of reality.    
\end{quotation}

\begin{itemize}
  \item Natural user interfaces are a new way to interact with GUIs -- not something completely new
  \item However, it is important to not only learn from GUI development and apply them to NUI -- the NUI design is about how we interact with the GUI, and how well the GUI is opimised for and responds to "natural" forms of input such as touch, speech, and others where relevant.
  \item NUIs respond to everyday interactions instead of forcing the user into using a Tangible User Interface (TUI) like a computer mouse in order to manipulate digital information that the mouse is bad at manipulating (for example sketching and annotating)
  \item Technical challenge: recognise different forms of input (e.g., pen vs. mouse vs. touch) and prompt/respond differently/properly to type of input (especially separating between different TUIs like mouse and pen -- you only want to sketch/annotate with a pen). See Photoshop as example for this (pressure recognition, etc.)
\end{itemize}

Have designed a very commonly used system: an issue (task) tracker. Focus has been on optimising the actual board interaction for touch, as this is the natural interface type that should be expected to best optimise the key flows in the application (moving tasks back and forth between swimlanes as the status of the tasks changes).

with focus on natural (touch) interface which should optimise the key flows in the application: a task tracker.

\begin{itemize}
  \item NUI types: only touch (skin is unrelated to the domain, but gestures (e.g., with a kinect in a meeting room) is interesting, speech is unrelated unless the audience has no arms/ability to touch (disabled), gaze tracking is cool but unnecessary unless same as speech recognition, brain machine interface only relevant for heavily disabled users who are probably not in need of an issue tracker)
\end{itemize}
